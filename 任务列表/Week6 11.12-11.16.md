**学习时长**
11.12-11.16日

**学习目标**

1. 理解激活函数，权重初始化，batchnorm 对网络训练的影响
- slides: lecture06（ http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture06.pdf ）
- 观看视频 p14
- 学习神经网络笔记1（https://zhuanlan.zhihu.com/p/21462488?refer=intelligentunit ）
2. 深入理解 BatchNormalization
- slides: lecture06（ http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture06.pdf ）
- 观看视频 p15
- 学习神经网络笔记2（ https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit ）
3. 总结回顾和理解深度学习中 normalize 的技巧
- 阅读文章 深度学习中的 normalization 方法（https://zhuanlan.zhihu.com/p/33173246）

**作业**

1. 完成 assignment2 中 ``BatchNormalization.ipynb``
2. 完成 assignment2 中 ``Dropout.ipynb``

**参看文献**

[1] [Geoffrey E. Hinton et al, "Improving neural networks by preventing co-adaptation of feature detectors", arXiv 2012] (https://arxiv.org/abs/1207.0580)

**课程资料：**

课程主页： http://cs231n.stanford.edu /

course note： http://cs231n.github.io /

知乎翻译： https://zhuanlan.zhihu.com/p/21930884

推荐b站的视频观看  https://www.bilibili.com/video/av17204303/?p=3 

注册一个github账号: github.com
后续发布的一些project和exercise会在这个github下：https://github.com/orgs/sharedeeply/dashboard

配置环境：  https://github.com/sharedeeply/DeepLearning-StartKit